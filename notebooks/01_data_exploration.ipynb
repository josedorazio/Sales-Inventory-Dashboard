{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Superstore Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from typing import List\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Data Exploration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# Function to read and validate data\n",
    "# ---\n",
    "\n",
    "\n",
    "def read_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a CSV file into a pandas DataFrame and performs initial data checks.\n",
    "    Args:\n",
    "            file_path (str): The path to the CSV file.\n",
    "    Returns:\n",
    "            pd.DataFrame: The loaded DataFrame after performing checks.\n",
    "    Raises:\n",
    "            FileNotFoundError: If the specified file does not exist.\n",
    "            ValueError: If the DataFrame is empty.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        open(file_path, \"r\").close()\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"The file at {file_path} was not found.\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"The provided CSV file is empty.\")\n",
    "    print(f\"Reading File from: {file_path}\\n{'=' * 40}\")\n",
    "    print(f\"Dataframe Info:\\n{df.info()}\")\n",
    "    print(f\"{'=' *50} \\nUnique Values\")\n",
    "    print(df.nunique())\n",
    "    print(f\"{'=' *50} \\nChecking Duplicated Values:\")\n",
    "    duplicated = df.duplicated().sum()\n",
    "    if duplicated > 0:\n",
    "        print(f\"There are {duplicated} duplicated rows.\")\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        print(f\"Rows remaining after drop: {len(df)}\")\n",
    "    else:\n",
    "        print(f\"No duplicates âœ…\\n{'=' * 40}\")\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "\n",
    "df = read_data(\"../data/raw/Sample - Superstore.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Check Missing Values\n",
    "# ---------------------------------------------------\n",
    "\n",
    "\n",
    "def check_missing_values(df: pd.DataFrame):\n",
    "    print(\"Checking for Missing (Null/NaN) Values ðŸ”Ž\")\n",
    "    null_counts = df.isnull().sum()\n",
    "    null_percentage = (null_counts / len(df)) * 100\n",
    "\n",
    "    missing_data_report = pd.DataFrame(\n",
    "        {\"Missing Count\": null_counts, \"Missing %\": null_percentage}\n",
    "    )\n",
    "\n",
    "    # Filter to only show columns with missing values and sort\n",
    "    missing_data_report = missing_data_report[\n",
    "        missing_data_report[\"Missing Count\"] > 0\n",
    "    ].sort_values(by=\"Missing %\", ascending=False)\n",
    "\n",
    "    print(\"\\nMissing Value Report:\")\n",
    "\n",
    "    if not missing_data_report.empty:\n",
    "        print(\n",
    "            f\"Found {len(missing_data_report)} columns with missing values.ðŸš¨\"\n",
    "        )\n",
    "        print(\"-\" * 50)\n",
    "        # Use .to_string() for clean, non-truncated printing\n",
    "        print(missing_data_report.to_string(float_format=\"%.2f%%\"))\n",
    "        print(\"-\" * 50)\n",
    "    else:\n",
    "        print(\"No missing values detected. âœ…\")\n",
    "\n",
    "\n",
    "check_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# EDA - Step 4: Study Variables\n",
    "# ---------------------------------------------------\n",
    "def plot_numerical_distro(\n",
    "    df: pd.DataFrame, num_cols: List[str], bins: int = 30\n",
    "):\n",
    "    for col in num_cols:\n",
    "        print(f\"\\n --- Analysis for Column {col} ---\")\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "        # 1. Histogram (for distribution shape)\n",
    "        sns.histplot(\n",
    "            df[col].dropna(), kde=True, bins=bins, ax=axes[0], color=\"skyblue\"\n",
    "        )\n",
    "        axes[0].set_title(f\"Histogram & KDE for {col}\")\n",
    "        axes[0].set_xlabel(col)\n",
    "\n",
    "        # 2. Box Plot (for central tendency and outliers)\n",
    "        sns.boxplot(y=df[col].dropna(), ax=axes[1], color=\"lightcoral\")\n",
    "        axes[1].set_title(f\"Box Plot for {col}\")\n",
    "        axes[1].set_ylabel(col)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_categorical_variable(\n",
    "    df: pd.DataFrame, cat_cols: List[str], bins: int = 30\n",
    "):\n",
    "    for col in cat_cols:\n",
    "        print(f\"\\n --- Analysis for Column {col} ---\")\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.countplot(\n",
    "            y=df[col].dropna(),\n",
    "            order=df[col].value_counts().index,\n",
    "            palette=\"viridis\",\n",
    "        )\n",
    "        for container in plt.gca().containers:\n",
    "            plt.bar_label(container)\n",
    "\n",
    "        plt.title(f\"Frequency Count of Categories for {col}\", fontsize=14)\n",
    "        plt.xlabel(\"Count\", fontsize=12)\n",
    "        plt.ylabel(col, fontsize=12)\n",
    "        plt.grid(axis=\"x\", alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def variable_study(df: pd.DataFrame, status: str = \"num\"):\n",
    "    if status == \"num\":\n",
    "        print(f\"{'='*50} \\n Numerical Variable Study\")\n",
    "        print(df.describe().T)\n",
    "        numerical_var = df.select_dtypes(include=\"number\")\n",
    "        plot_numerical_distro(df, numerical_var)\n",
    "    if status == \"cat\":\n",
    "        print(f\"{'='*50} \\n Categorical Variable Study\")\n",
    "        categorical_var = df.select_dtypes(exclude=\"number\")\n",
    "        plot_categorical_variable(df, categorical_var)\n",
    "    else:\n",
    "        print(\"No categorical or Numerical Variable\")\n",
    "\n",
    "\n",
    "variable_study(df, \"num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_study(df, \"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Formatting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Convert Date Columns to Datetime\n",
    "# ---------------------------------------------------\n",
    "\n",
    "\n",
    "def convert_to_datetime(df: pd.DataFrame, date_columns: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts specified columns in the DataFrame to datetime format.\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        date_columns (list): List of column names to convert to datetime.\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with converted date columns.\n",
    "    \"\"\"\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "            if df[col].isnull().any():\n",
    "                print(\n",
    "                    f\"Warning: Some values in column '{col}' could not be converted and are set to NaT.\"\n",
    "                )\n",
    "        else:\n",
    "            print(f\"Column '{col}' not found in DataFrame.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "df_2 = convert_to_datetime(df, [\"Order Date\", \"Ship Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Standardize Column Names\n",
    "# ---------------------------------------------------\n",
    "\n",
    "\n",
    "def column_names_standardize(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardizes column names by converting to lowercase and replacing spaces with underscores.\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with standardized column names.\n",
    "    \"\"\"\n",
    "    df.columns = [col.lower().replace(\" \", \"_\") for col in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "df_3 = column_names_standardize(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Data Validation\n",
    "# ---------------------------------------------------\n",
    "\n",
    "\n",
    "def validate_data(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Validates data by checking for negative values in specific columns.\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "    \"\"\"\n",
    "    numeric_cols = [\"sales\", \"profit\", \"quantity\", \"discount\"]\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            negative_count = (df[col] < 0).sum()\n",
    "            if negative_count > 0:\n",
    "                print(\n",
    "                    f\"Warning: Column '{col}' contains {negative_count} negative values.\"\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Column '{col}' has no negative values. âœ…\")\n",
    "        else:\n",
    "            print(f\"Column '{col}' not found in DataFrame.\")\n",
    "    if df[\"discount\"].max() > 1:\n",
    "        print(\"Warning: 'discount' column has values greater than 1 (100%).\")\n",
    "    elif df[\"discount\"].min() < 0:\n",
    "        print(\"Warning: 'discount' column has negative values.\")\n",
    "    else:\n",
    "        print(\n",
    "            \"Column 'discount' column values are within the expected range (0 to 1). âœ…\"\n",
    "        )\n",
    "    print(\n",
    "        \"All order dates are bigger than ship dates. âœ…\"\n",
    "        if (df[\"order_date\"] <= df[\"ship_date\"]).all()\n",
    "        else \"Warning: Some order dates are after ship dates.ðŸš¨\"\n",
    "    )\n",
    "\n",
    "\n",
    "validate_data(df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.to_csv(\"../data/processed/Superstore-processed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
